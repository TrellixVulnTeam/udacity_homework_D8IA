{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战\n",
    "### 答题者：骆炜\n",
    "### 目标要求：0.06127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗\n",
    "结合当前精确度要求最高的直接从Keras可以获得的Xception，Inception-Resnet和Resnet50训练好的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libs\n",
    "from keras.applications import xception, resnet50, inception_resnet_v2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成Symbol link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from https://github.com/ypwhs/dogs_vs_cats\n",
    "train_filenames = os.listdir('train')\n",
    "train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "\n",
    "def rmrf_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "rmrf_mkdir('train2')\n",
    "os.mkdir('train2/cat')\n",
    "os.mkdir('train2/dog')\n",
    "\n",
    "rmrf_mkdir('test2')\n",
    "os.symlink('../test/', 'test2/test')\n",
    "\n",
    "for filename in train_cat:\n",
    "    os.symlink('../../train/'+filename, 'train2/cat/'+filename)\n",
    "\n",
    "for filename in train_dog:\n",
    "    os.symlink('../../train/'+filename, 'train2/dog/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageNet中属于猫狗的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型\n",
    "MODELS = {\n",
    "    \"xception\": xception.Xception,\n",
    "    \"resnet\": resnet50.ResNet50,\n",
    "    \"inception\": inception_resnet_v2.InceptionResNetV2\n",
    "}\n",
    "# 预处理\n",
    "PREPROCESS = {\n",
    "    \"xception\": xception.preprocess_input, \n",
    "    \"resnet\": resnet50.preprocess_input,\n",
    "    \"inception\": inception_resnet_v2.preprocess_input\n",
    "}\n",
    "# 预测函数\n",
    "DECODE = {\n",
    "    \"xception\": xception.decode_predictions, # TensorFlow ONLY\n",
    "    \"resnet\": resnet50.decode_predictions,\n",
    "    \"inception\": inception_resnet_v2.decode_predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试部分\n",
    "以下部分为示意，实际代码中这部分作为一个函数，分别运行两次对猫狗进行判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最终结果的字典\n",
    "sum_result = {}\n",
    "\n",
    "# 依次运行三个模型\n",
    "for i in MODELS.keys():\n",
    "    print(\"[INFO] loading {}...\".format(i))\n",
    "    Network = MODELS[i]\n",
    "    model = Network(weights=\"imagenet\") # 载入ImageNet预训练权重\n",
    "    if i == \"resnet\":\n",
    "        inputShape = (224, 224)  # resnet 的输入图像尺寸\n",
    "    else:\n",
    "        inputShape = (299, 299)  # inception相关的输入图像尺寸\n",
    "\n",
    "    print(\"[INFO] loading and pre-processing {} image...\".format('*根据训练输入猫/狗*'))\n",
    "\n",
    "    # 每个分类有12500张照片\n",
    "    for j in range(12500):\n",
    "        image_name = '*载入图片的位置，以jpg结尾，j为图片的索引*'\n",
    "        image = load_img(image_name, target_size=inputShape)\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        x = PREPROCESS[i](image)\n",
    "        preds = model.predict(x)\n",
    "        # 取top-10作为结果\n",
    "        decode_res = DECODE[i](preds, top=10)[0]\n",
    "        # 将所有前10的index取出来\n",
    "        preds_result = list(map(lambda x: decode_res[x][0], range(10)))\n",
    "        # 是否在预测中有属于猫狗的分类?\n",
    "        if '*所要判断的种类*' == 'dog':\n",
    "            is_DC = True in list(map(lambda x: x in dogs, preds_result))\n",
    "        else: # 猫\n",
    "            is_DC = True in list(map(lambda x: x in cats, preds_result))\n",
    "        # 对于每个照片j，每个判断结果存储下来\n",
    "        if str(j) in sum_result.keys():\n",
    "            sum_result[str(j)].append(is_DC)\n",
    "        else:\n",
    "            sum_result[str(j)]=[is_DC]\n",
    "\n",
    "# 存储移除列表\n",
    "remove_list = []\n",
    "# 如果一个True都没有，即判断不出有猫狗\n",
    "for i in sum_result.keys():\n",
    "    if True not in sum_result[i]:\n",
    "        remove_list.append(i)\n",
    "\n",
    "# 将结果输出，以后待用\n",
    "np.save('*将文件存为npy文件*'+'.npy', remove_list)\n",
    "f_o = open('*将文件存为txt文件（比较直观）*'+'.txt', 'w')\n",
    "if len(remove_list)>0:\n",
    "    for ele in remove_list:\n",
    "        f_o.write(ele+'\\n')\n",
    "    f_o.close()\n",
    "else:\n",
    "    f_o.write('nothing to save')\n",
    "    f_o.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imgaug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59ce7a04ab72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maugmenters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imgaug'"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# imgaug 源自https://github.com/aleju/imgaug\n",
    "# 混合数据增强函数\n",
    "def aug_mix(image,\n",
    "            augmenters_param={'Flip':1,\n",
    "                              'Colorspace':((10,50)),\n",
    "                              'GaussianBlur':(0.0,3.0),\n",
    "                              'Dropout':((0,0.2),0.5),\n",
    "                              'Multiply':((0.5,1.5),0.5),\n",
    "                              'Crop':(-0.2,-0.1)}):\n",
    "    images=np.zeros((15,image.shape[0],image.shape[1],image.shape[2]))\n",
    "    \n",
    "    # 考虑到生成数据的数量，直选了4种处理方法，一张照片生成6个增强后照片\n",
    "    augmenters_param_={'Flip':0,\n",
    "                      'Colorspace':0,\n",
    "                      'GaussianBlur':0,\n",
    "                      'Dropout':(0,1),\n",
    "                      }\n",
    "    i=0\n",
    "    flag=[]\n",
    "    for aug1 in augmenters_param:\n",
    "        for aug2 in [x for x in augmenters_param if x!=aug1]:\n",
    "            if (aug2,aug1) in flag:\n",
    "                continue\n",
    "            flag.append((aug1,aug2))\n",
    "            augmenters_param_copy=copy.deepcopy(augmenters_param_)\n",
    "            augmenters_param_copy[aug1]=augmenters_param[aug1]\n",
    "            augmenters_param_copy[aug2]=augmenters_param[aug2]\n",
    "            seq=iaa.Sequential([\n",
    "                iaa.Fliplr(augmenters_param_copy['Flip']),\n",
    "                iaa.WithColorspace(to_colorspace='HSV',from_colorspace='RGB',children=iaa.WithChannels(0,iaa.Add(augmenters_param_copy['Colorspace']))),\n",
    "                iaa.GaussianBlur(sigma=augmenters_param_copy['GaussianBlur']),\n",
    "                iaa.Dropout(p=augmenters_param_copy['Dropout'][0],per_channel=augmenters_param_copy['Dropout'][1])\n",
    "            ])\n",
    "            seq_det = seq.to_deterministic()\n",
    "            image_aug = seq_det.augment_images([image])[0]\n",
    "            images[i] = image_aug\n",
    "            i += 1\n",
    "    return images\n",
    "\n",
    "\n",
    "def select_x(x):\n",
    "    if x>=640:\n",
    "        x=635\n",
    "    elif x<0:\n",
    "        x=5\n",
    "    return x\n",
    "\n",
    "\n",
    "def select_y(y):\n",
    "    if y>=480:\n",
    "        y=475\n",
    "    elif y<0:\n",
    "        y=5\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from data_aug_tool import *\n",
    "\n",
    "# 对狗的照片进行处理\n",
    "img_path='./train2/dog/'\n",
    "img_list = os.listdir(img_path)\n",
    "img_num = len(img_list)\n",
    "start_num = 12500\n",
    "\n",
    "for i in range(img_num):\n",
    "    img_i_path = os.path.join(img_path, img_list[i])\n",
    "    image = Image.open(img_i_path)\n",
    "    image = np.asanyarray(image, dtype = 'uint8')\n",
    "    image_aug=aug_mix(image)\n",
    "    # 生成6张照片\n",
    "    for j in range(6):\n",
    "        plt.imsave(os.path.join('./dogtesting/','dog.'+'{}'.format(str(i*6+j+start_num))+'.jpg'),\n",
    "                   image_aug[j].astype('uint8'))\n",
    "\n",
    "# 对猫的照片进行处理\n",
    "img_path='./train2/cat/'\n",
    "img_list = os.listdir(img_path)\n",
    "img_num = len(img_list)\n",
    "\n",
    "for i in range(img_num):\n",
    "    img_i_path = os.path.join(img_path, img_list[i])\n",
    "    image = Image.open(img_i_path)\n",
    "    image = np.asanyarray(image, dtype = 'uint8')\n",
    "    image_aug=aug_mix(image)\n",
    "    for j in range(6):\n",
    "        plt.imsave(os.path.join('./cattesting/','cat.'+'{}'.format(str(i*6+j+start_num))+'.jpg'),\n",
    "                   image_aug[j].astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成特征向量\n",
    "这部分代码借鉴了 https://github.com/ypwhs/dogs_vs_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, GlobalAveragePooling2D\n",
    "from keras.applications import xception, resnet50, inception_resnet_v2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "MODELS = {\n",
    "    \"xception\": xception.Xception,\n",
    "    \"resnet\": resnet50.ResNet50,\n",
    "    \"inception\": inception_resnet_v2.InceptionResNetV2\n",
    "}\n",
    "\n",
    "PREPROCESS = {\n",
    "    \"xception\": xception.preprocess_input, \n",
    "    \"resnet\": resnet50.preprocess_input,\n",
    "    \"inception\": inception_resnet_v2.preprocess_input\n",
    "}\n",
    "\n",
    "SHAPE = {\n",
    "    \"xception\": (299, 299),\n",
    "    \"resnet\": (224, 224),\n",
    "    \"inception\": (299, 299)\n",
    "}\n",
    "\n",
    "def write_gap(MODEL, image_size, func_name, lambda_func=None, B_size=16):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(\"train2\", image_size, shuffle=False, batch_size=B_size)\n",
    "    test_generator = gen.flow_from_directory(\"test2\", image_size, shuffle=False,\n",
    "                                             batch_size=B_size, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator) \n",
    "    test = model.predict_generator(test_generator)\n",
    "    with h5py.File(\"gap_%s.h5\"%func_name) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 载入三个模型并将特征向量存于'.h5'文件中\n",
    "    for i in MODELS.keys():\n",
    "        write_gap(MODELS[i], SHAPE[i], i, PREPROCESS[i], B_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练并输出结果\n",
    "这部分代码借鉴了https://github.com/ypwhs/dogs_vs_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Input, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for file_name in [\"gap_inception.h5\", \"gap_resnet.h5\", \"gap_xception.h5\"]:\n",
    "    with h5py.File('./'+file_name, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=8, validation_split=0.2)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"test2\", (224, 224), shuffle=False, batch_size=64)\n",
    "df = pd.read_csv('sample_submission.csv')\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('submission.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
